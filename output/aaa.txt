Codebase Analysis for: .

Directory Structure:
└── .
    ├── requirements.txt (15 bytes)
    ├── .github
    │   └── workflows
    │       ├── deploy.yml (1298 bytes)
    │       ├── codebase_dump.yml (677 bytes)
    │       └── test.yml (992 bytes)
    ├── .cdigestignore (38 bytes)
    ├── Readme.md (3709 bytes)
    ├── setup.py (666 bytes)
    ├── tests
    │   ├── test_codebase_analysis.py (2016 bytes)
    │   ├── test_node_models.py (4806 bytes)
    │   └── test_ignore_patterns_manager.py (8681 bytes)
    └── src
        └── codebase_dump
            ├── app.py (3354 bytes)
            ├── __init__.py (0 bytes)
            └── core
                ├── __init__.py (0 bytes)
                ├── codebase_analysis.py (3242 bytes)
                ├── output_formatter.py (4321 bytes)
                ├── models.py (3617 bytes)
                └── ignore_patterns_manager.py (4167 bytes)

Summary:
Total files analyzed: 17
Total directories analyzed: 6
Estimated output size: 40.62 KB
Actual analyzed size: 40.62 KB
Total tokens: 8623
Actual text content size: 40.62 KB

File Contents:

==================================================
File: ./requirements.txt
==================================================
tiktoken>=0.8.0

==================================================
File: ./.github/workflows/deploy.yml
==================================================
name: Deploy to PyPI

on:
  push:
    tags:
      - "v*"
  pull_request:
    branches:
      - main

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install setuptools wheel twine
          pip install -r requirements.txt
          pip install -e .[dev]

      - name: Run tests
        run: |
          pytest tests/

      - name: Build package
        run: |
          python setup.py sdist bdist_wheel

      - name: Publish to Test PyPI
        # if: startsWith(github.ref, 'refs/tags')
        env:
          TWINE_USERNAME: ${{ secrets.TEST_PYPI_USERNAME }}
          TWINE_PASSWORD: ${{ secrets.TEST_PYPI_PASSWORD }}
        run: |
          python -m twine upload --repository-url https://test.pypi.org/legacy/ dist/* --verbose

      - name: Publish to PyPI
        # if: startsWith(github.ref, 'refs/tags')
        env:
          TWINE_USERNAME: ${{ secrets.PYPI_USERNAME }}
          TWINE_PASSWORD: ${{ secrets.PYPI_PASSWORD }}
        run: |
          python -m twine upload dist/* --verbose

==================================================
File: ./.github/workflows/codebase_dump.yml
==================================================
name: Generate Project Dump for LLM

on:
  workflow_dispatch:

jobs:
  generate-file:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: "3.10"

      - name: Install Codebase Dump
        run: pip install codebase-dump

      - name: Generate Single-File Prompt for LLM
        run: codebase-dump . -f project_dump_for_llm.md -o markdown 

      - name: Upload Prompt File as Artifact
        uses: actions/upload-artifact@v3
        with:
          name: project_dump_for_llm.md
          path: project_dump_for_llm.md

==================================================
File: ./.github/workflows/test.yml
==================================================
name: Test and Lint

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install setuptools flake8
          pip install -r requirements.txt
          pip install -e .[dev] 

      - name: Lint with flake8
        run: |
          # stop the build if there are Python syntax errors or undefined names
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
          # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
          flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

      - name: Run tests
        run: |
          pytest tests/

==================================================
File: ./.cdigestignore
==================================================
# My gitignore file
./output
.DS_Store

==================================================
File: ./Readme.md
==================================================
# Readme 

This project is a lightweight version of [Codebase Digest](https://github.com/kamilstanuch/codebase-digest), designed to analyze and summarize your codebase into a single-file dump. The generated output includes:
- Code structure and contents
- A basic summary of the codebase

This output can be used as input for Large Language Models (LLMs) like ChatGPT, Google Gemini, and others for further analysis or to support prompt-based tasks.

For inspiration on possible prompts, refer to the [LLM Prompts section](https://github.com/kamilstanuch/codebase-digest?tab=readme-ov-file#llm-prompts-for-enhanced-analysis) in the Codebase Digest repository.

# How to use

## Installation

### Option 1: Install via pip

You can install codebase-dump directly from PyPI:

```bash
pip install codebase-dump
```

### Option 2: Install by Cloning the Repository

Clone setup repository 

```bash
git clone https://github.com/your-username/codebase-dump.git
cd codebase-dump
pip install -r requirements.txt
```

I recommend opening this project in Visual Studio Code and setting up a virtual environment. 

## Usage

### Command Line
Once installed, you can run codebase-dump from the command line:

```bash
codebase-dump <path_to_codebase> -f <output_filename> -o <output_format>
```

For example, to generate a markdown file of your project’s code structure:

```bash
codebase-dump . -f project_dump_for_llm.md -o markdown
```

### Available Arguments

| Option | Description |
|--------|-------------|
| `path_to_directory` | Path to the directory you want to analyze |
| `-o, --output-format` | Output format (text, markdown). Default: text |
| `-f, --file` | Output file name |
| `--max-size` | Maximum allowed text content size in KB (default: 10240 KB) |

### From Source

You can also run codebase-dump directly from the source code:

```bash
python app.py <path_to_codebase> -f <output_filename> -o <output_format>
```

### Usage in GitHub Actions
You can automate codebase-dump in a GitHub Actions workflow to generate and save the code dump as an artifact. Here’s an example workflow configuration (working example available in this own repository: [.github/workflows/codebase_dump.yml](.github/workflows/codebase_dump.yml)).


```yaml
name: Generate Project Dump for LLM

on:
  workflow_dispatch:

jobs:
  generate-file:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: "3.10"

      - name: Install codebase-dump
        run: pip install codebase-dump

      - name: Generate Single-File Prompt for LLM
        run: codebase-dump . -f project_dump_for_llm.md -o markdown 

      - name: Upload Prompt File as Artifact
        uses: actions/upload-artifact@v3
        with:
          name: project_dump_for_llm.md
          path: project_dump_for_llm.md
```

In this example:

- The workflow is triggered manually with workflow_dispatch.
- It installs codebase-dump and generates a .md file named project_dump_for_llm.md, containing the code structure and summary.
- The generated file is then uploaded as an artifact for easy access and download.

## What next?

Once you get your codebase dump, copy that into one of LLMs as input prompt and start asking Gemini, ChatGPT, Claude and others questions related to your codebase. For example, ask about "what are suggested steps to refactor this code into //your choice// architecture.". 

For inspiration on possible prompts, check [LLM Prompts section](https://github.com/kamilstanuch/codebase-digest?tab=readme-ov-file#llm-prompts-for-enhanced-analysis) in the Codebase Digest repository.


==================================================
File: ./setup.py
==================================================
from setuptools import setup, find_packages

setup(
    name="codebase-dump",
    version="0.1.5",
    description="Generate a single-file dump of your repository, so you can use it as LLM input",
    author="Mirek Stanek, Kamil Stanuch",
    author_email="mirek@practicalengineering.management, kamil@stanuch.eu",
    packages=find_packages("src"),
    package_dir={"": "src"},
    install_requires=["tiktoken"],  # List core dependencies here
    extras_require={
        "dev": ["pytest", "twine"]  # Development dependencies
    },
    entry_points={
    'console_scripts': [
        'codebase-dump=codebase_dump.app:main',
    ]},
    python_requires=">=3.7",
)

==================================================
File: ./tests/test_codebase_analysis.py
==================================================
import unittest
from unittest.mock import patch, mock_open
from codebase_dump.core.codebase_analysis import CodebaseAnalysis
from codebase_dump.core.models import DirectoryAnalysis, TextFileAnalysis
from codebase_dump.core.ignore_patterns_manager import IgnorePatternManager

class TestCodebaseAnalysis(unittest.TestCase):

    @patch("codebase_dump.core.codebase_analysis.os.listdir", return_value=["file1.txt", "file2.txt"])
    @patch('codebase_dump.core.codebase_analysis.os.path.isfile', return_value=True)
    @patch('codebase_dump.core.codebase_analysis.os.path.getsize', return_value=10)
    @patch("builtins.open", new_callable=mock_open, read_data="Loremm ipsum dolor sit amet")
    def test_analyze_directory_basic(self, mock_read, mock_file, mock_isfile, mock):
         ignore_manager = IgnorePatternManager(".", load_default_ignore_patterns=False)
         codebase_analysis = CodebaseAnalysis()
         result = codebase_analysis.analyze_directory(".", ignore_manager, ".", max_depth=10)
         self.assertEqual(len(result.children), 2)
         self.assertEqual(result.children[0].name, "file1.txt")
         self.assertEqual(result.children[1].name, "file2.txt")

    @patch("codebase_dump.core.codebase_analysis.os.listdir", return_value=["file1.txt", "file2.py"])
    @patch('codebase_dump.core.codebase_analysis.os.path.isfile', return_value=True)
    @patch('codebase_dump.core.codebase_analysis.os.path.getsize', return_value=10)
    @patch("builtins.open", new_callable=mock_open, read_data="Loremm ipsum dolor sit amet")
    def test_analyze_directory_with_ignored(self, mock_read, mock_file, mock_isfile, mock):
         ignore_manager = IgnorePatternManager(".", load_default_ignore_patterns=False, extra_ignore_patterns=["*.py"])
         codebase_analysis = CodebaseAnalysis()
         result = codebase_analysis.analyze_directory(".", ignore_manager, ".", max_depth=10)
         self.assertEqual(len(result.children), 1)
         self.assertEqual(result.children[0].name, "file1.txt")

==================================================
File: ./tests/test_node_models.py
==================================================
import unittest
from codebase_dump.core.models import NodeAnalysis, DirectoryAnalysis, TextFileAnalysis

class TestNodeAnalysis(unittest.TestCase):
    
        def test_node_analysis(self):
            node = NodeAnalysis("test")
            self.assertEqual(node.name, "test")
    
        def test_directory_analysis(self):
            directory = DirectoryAnalysis("test")
            self.assertEqual(directory.name, "test")
            self.assertEqual(directory.type, "directory")
    
        def test_text_file_analysis(self):
            text_file = TextFileAnalysis("test")
            self.assertEqual(text_file.name, "test")
            self.assertEqual(text_file.type, "text_file")

        def test_empty_directory_analysis(self):
            directory = DirectoryAnalysis("test")
            self.assertEqual(directory.get_file_count(), 0)
            self.assertEqual(directory.get_dir_count(), 0)
            self.assertEqual(directory.get_total_tokens(), 0)
            self.assertEqual(directory.get_non_ignored_text_content_size(), 0)
            self.assertEqual(directory.size, 0)
        
        def test_directory_with_one_text_file(self):
            directory = DirectoryAnalysis("test")
            text_file = TextFileAnalysis("test")
            text_file.file_content = "length of this string is 27"

            directory.children.append(text_file)
            self.assertEqual(directory.get_file_count(), 1)
            self.assertEqual(directory.get_dir_count(), 0)
            self.assertEqual(directory.get_non_ignored_text_content_size(), 27)
            self.assertEqual(directory.size, 27)

        def test_directory_with_ten_files(self):
            directory = DirectoryAnalysis("test")
            for i in range(10):
                text_file = TextFileAnalysis("test")
                text_file.file_content = "length of this string is 27"
                directory.children.append(text_file)
            self.assertEqual(directory.get_file_count(), 10)
            self.assertEqual(directory.get_dir_count(), 0)
            self.assertEqual(directory.get_non_ignored_text_content_size(), 270)
            self.assertEqual(directory.size, 270)

        def test_directory_with_one_sub_directory(self):
            directory = DirectoryAnalysis("test")
            sub_directory = DirectoryAnalysis("test")
            text_file = TextFileAnalysis("test")
            text_file.file_content = "length of this string is 27"
            sub_directory.children.append(text_file)
            directory.children.append(sub_directory)
            self.assertEqual(directory.get_file_count(), 1)
            self.assertEqual(directory.get_dir_count(), 1)
            self.assertEqual(directory.get_non_ignored_text_content_size(), 27)
            self.assertEqual(directory.size, 27)

        def test_directory_with_one_ignored_file(self):
            directory = DirectoryAnalysis("test")
            text_file = TextFileAnalysis("test")
            text_file.is_ignored = True
            text_file.file_content = "length of this string is 27"
            directory.children.append(text_file)
            self.assertEqual(directory.get_file_count(), 0)
            self.assertEqual(directory.get_dir_count(), 0)
            self.assertEqual(directory.get_non_ignored_text_content_size(), 0)
            self.assertEqual(directory.size, 27)

        def test_directory_with_one_ignored_sub_directory(self):
            directory = DirectoryAnalysis("test")
            sub_directory = DirectoryAnalysis("test")
            sub_directory.is_ignored = True
            text_file = TextFileAnalysis("test")
            text_file.file_content = "length of this string is 27"
            sub_directory.children.append(text_file)
            directory.children.append(sub_directory)
            self.assertEqual(directory.get_file_count(), 0)
            self.assertEqual(directory.get_dir_count(), 0)
            self.assertEqual(directory.get_non_ignored_text_content_size(), 0)
            self.assertEqual(directory.size, 27)

        def test_directory_with_one_ignored_file_and_one_text_file(self):
            directory = DirectoryAnalysis("test")
            text_file = TextFileAnalysis("test")
            text_file.is_ignored = True
            text_file.file_content = "length of this string is 27"
            directory.children.append(text_file)
            text_file = TextFileAnalysis("test")
            text_file.file_content = "length of this string is 27"
            directory.children.append(text_file)
            self.assertEqual(directory.get_file_count(), 1)
            self.assertEqual(directory.get_dir_count(), 0)
            self.assertEqual(directory.get_non_ignored_text_content_size(), 27)
            self.assertEqual(directory.size, 54)

==================================================
File: ./tests/test_ignore_patterns_manager.py
==================================================
import os
import unittest
from unittest.mock import patch, mock_open
from codebase_dump.core.ignore_patterns_manager import IgnorePatternManager

class TestIgnorePatternsManager(unittest.TestCase):
        
        def test_ignore_patterns_manager_should_load_default_patterns(self):
            manager = IgnorePatternManager("./test", 
                                           load_default_ignore_patterns=True,
                                           load_gitignore=False,
                                           load_cdigestignore=False)
            self.assertSetEqual(manager.ignore_patterns_as_str, set(IgnorePatternManager.DEFAULT_IGNORE_PATTERNS))

        @patch('codebase_dump.core.ignore_patterns_manager.os.path.exists', return_value=True)
        @patch("builtins.open", new_callable=mock_open, read_data=".java\n.class\n#comment\n")
        def test_load_cdigestignore(self, mock_file, mock_exists):
            manager = IgnorePatternManager("./test", 
                                           load_default_ignore_patterns=False,
                                           load_gitignore=False, 
                                           load_cdigestignore=True)
            
            mock_file.assert_called_once_with("./test/.cdigestignore", "r")
            self.assertSetEqual(manager.ignore_patterns_as_str, set([".java", ".class"]))

        @patch('codebase_dump.core.ignore_patterns_manager.os.path.exists', return_value=True)
        def test_load_both_gitignore_and_cdigestignore(self, mock_exists):
            def mock_open_side_effect(path, mode="r"):
                if path.endswith(".cdigestignore"):
                    return mock_open(read_data=".java\n")()  # Mock for .cdigestignore
                elif path.endswith(".gitignore"):
                    return mock_open(read_data=".py\n")()  # Mock for .gitignore
                else:
                    raise FileNotFoundError(f"Unexpected file opened: {path}")  # Catch unexpected file opens

            with patch("builtins.open", new_callable=mock_open) as mock_file:
                mock_file.side_effect = mock_open_side_effect
                manager = IgnorePatternManager("./test", load_default_ignore_patterns=False,
                                                load_gitignore=True, load_cdigestignore=True)

            self.assertSetEqual(manager.ignore_patterns_as_str, {".java", ".py"})

        @patch('codebase_dump.core.ignore_patterns_manager.os.path.exists', return_value=True)
        @patch("builtins.open", new_callable=mock_open, read_data=".java\n.class\n#comment\n")
        def test_load_gitignore(self, mock_file, mock_exists):
            manager = IgnorePatternManager("./test", load_default_ignore_patterns=False,
                                            load_gitignore=True, load_cdigestignore=False)
            self.assertSetEqual(manager.ignore_patterns_as_str, set([".java", ".class"]))

        @patch('codebase_dump.core.ignore_patterns_manager.os.path.exists', return_value=True)
        @patch("builtins.open", new_callable=mock_open, read_data=".java\n.class\n#comment\n")
        def test_load_gitignore_and_default(self, mock_file, mock_exists):
            manager = IgnorePatternManager("./test", load_default_ignore_patterns=True,
                                            load_gitignore=True, load_cdigestignore=False)
            
            expected_patterns = set(IgnorePatternManager.DEFAULT_IGNORE_PATTERNS)
            expected_patterns.update([".java", ".class"])

            self.assertSetEqual(manager.ignore_patterns_as_str, expected_patterns)
        
        def test_load_extra_patterns(self):
            manager = IgnorePatternManager("./test", load_default_ignore_patterns=False,
                                        load_gitignore=False, load_cdigestignore=False,
                                        extra_ignore_patterns={"extra1", "extra2"})
            self.assertSetEqual(manager.ignore_patterns_as_str, {"extra1", "extra2"})

        def test_should_ignore_filename(self):
            manager = IgnorePatternManager("./test", load_default_ignore_patterns=False,
                                        load_gitignore=False, load_cdigestignore=False,
                                        extra_ignore_patterns={"test.txt"})
            self.assertTrue(manager.should_ignore("./test/test.txt", "./test"))
            self.assertFalse(manager.should_ignore("./test/other.txt", "./test"))

        def test_should_ignore_relative_path(self):
            manager = IgnorePatternManager("./test", load_default_ignore_patterns=False,
                                        load_gitignore=False, load_cdigestignore=False,
                                        extra_ignore_patterns={"sub/test.txt"})
            self.assertTrue(manager.should_ignore("./test/sub/test.txt", "./test"))
            self.assertFalse(manager.should_ignore("./test/sub/other.txt", "./test"))
            self.assertFalse(manager.should_ignore("./test/test.txt", "./test")) # Test that only the relative path is matched


        def test_should_ignore_absolute_path(self):
            base_path = os.path.abspath("./test")  # Get absolute path
            manager = IgnorePatternManager("./test", load_default_ignore_patterns=False,
                                            load_gitignore=False, load_cdigestignore=False,
                                            extra_ignore_patterns={os.path.join(base_path, "sub/test.txt")})
            
            self.assertTrue(manager.should_ignore(os.path.join(base_path, "sub/test.txt"), base_path))
            self.assertFalse(manager.should_ignore(os.path.join(base_path, "sub/other.txt"), base_path))


        def test_should_ignore_leading_slash_absolute_path(self):
            base_path = os.path.abspath("./test")  # Get absolute path
            absolute_path_pattern = os.path.join(base_path, "sub/test.txt")
            manager = IgnorePatternManager("./test", load_default_ignore_patterns=False,
                                        load_gitignore=False, load_cdigestignore=False,
                                        extra_ignore_patterns={absolute_path_pattern})
            self.assertTrue(manager.should_ignore(os.path.join(base_path, "sub/test.txt"), base_path))
            self.assertFalse(manager.should_ignore(os.path.join(base_path, "sub/other.txt"), base_path))
            self.assertFalse(manager.should_ignore(os.path.join(base_path, "test.txt"), base_path))

        def test_should_ignore_part_of_relative_path(self):
            manager = IgnorePatternManager("./test", load_default_ignore_patterns=False,
                                        load_gitignore=False, load_cdigestignore=False,
                                        extra_ignore_patterns={"sub"}) # Ignores anything containing "sub" in the path
            self.assertTrue(manager.should_ignore("./test/sub/test.txt", "./test"))
            self.assertTrue(manager.should_ignore("./test/deeper/sub/test.txt", "./test"))
            self.assertFalse(manager.should_ignore("./test/other/test.txt", "./test"))

        def test_ignore_directory_pattern(self):
            manager = IgnorePatternManager("./test", load_default_ignore_patterns=False,
                                            load_gitignore=False, load_cdigestignore=False,
                                            extra_ignore_patterns={"sub/"})
            self.assertTrue(manager.should_ignore("./test/sub", "./test"))
            self.assertFalse(manager.should_ignore("./test/sub.txt", "./test"))

        def test_ignore_recursive_wildcard_pattern(self):
            manager = IgnorePatternManager("./test", load_default_ignore_patterns=False,
                                            load_gitignore=False, load_cdigestignore=False,
                                            extra_ignore_patterns={"**/logs", "**/*.tmp"})
            self.assertTrue(manager.should_ignore("./test/logs", "./test"))
            self.assertTrue(manager.should_ignore("./test/sub/logs", "./test"))
            self.assertTrue(manager.should_ignore("./test/sub/file.tmp", "./test"))
            self.assertFalse(manager.should_ignore("./test/sub/file.txt", "./test"))

        def test_empty_pattern_handling(self):
            manager = IgnorePatternManager("./test", load_default_ignore_patterns=False,
                                            load_gitignore=False, load_cdigestignore=False,
                                            extra_ignore_patterns={"", "# Comment only"})
            self.assertFalse(manager.should_ignore("./test/file.txt", "./test"))  # No patterns should ignore anything

==================================================
File: ./src/codebase_dump/app.py
==================================================
import argparse
import sys
import os

from codebase_dump.core.ignore_patterns_manager import IgnorePatternManager
from codebase_dump.core.codebase_analysis import CodebaseAnalysis
from codebase_dump.core.output_formatter import OutputFormatterBase, MarkdownOutputFormatter, PlainTextOutputFormatter

def main():
    parser = argparse.ArgumentParser(
        description="Generate a single-file dump of your repository, so you can use it as LLM input.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("path", nargs="?", help="Path to the directory to analyze")
    parser.add_argument("--max-size", type=int, default=10240, help="Maximum allowed text content size in KB (default: 10240 KB)")
    parser.add_argument("-o", "--output-format", choices=["text", "markdown"], default="text", help="Output format (default: text)")
    parser.add_argument("-f", "--file", help="Output file name (default: <directory_name>_codebase_dump.<format_extension>)")
    
    if len(sys.argv) == 1:
        parser.print_help(sys.stderr)
        sys.exit(1)

    args = parser.parse_args()

    if not args.path:
        print("Error: Path argument is required.")
        parser.print_help(sys.stderr)
        sys.exit(1)

    ignore_patterns_manager = IgnorePatternManager(args.path)
    codebase_analysis = CodebaseAnalysis()

    print(f"Debug: Ignore patterns after load_ignore_patterns: {ignore_patterns_manager.ignore_patterns}")

    print("Codebase Digest")
    print("Analyzing directory: " + args.path)
    
    data = codebase_analysis.analyze_directory(args.path, ignore_patterns_manager, args.path)
    
    total_size = data.size
    estimated_output_size = data.get_non_ignored_text_content_size()
    estimated_output_size += data.get_file_count() * 100  # Assume 100 bytes per file for structure
    estimated_output_size += 1000  # Add 1KB for summary
    print(f"Estimated output size: {estimated_output_size / 1024:.2f} KB")
    if estimated_output_size / 1024 > args.max_size:
        print(f"\nWarning: The estimated output size ({estimated_output_size / 1024:.2f} KB) exceeds the maximum allowed size ({args.max_size} KB).")
    elif total_size / 1024 > args.max_size * 2:  # Only show this if total size is significantly larger
        print(f"\nNote: The total size of all text files in the directory ({total_size / 1024:.2f} KB) is significantly larger than the estimated output size.")
        print("This is likely due to large files or directories that will be ignored in the analysis.")

    output_formatter: OutputFormatterBase = None
    if args.output_format == "markdown":
        output_formatter = MarkdownOutputFormatter()
    else:
        output_formatter = PlainTextOutputFormatter()

    output = output_formatter.format(data)

    # Save the output to a file
    file_name = args.file or f"{os.path.basename(args.path)}_codebase_dump{output_formatter.output_file_extension()}"
    full_path = os.path.abspath(file_name)
    os.makedirs(os.path.dirname(full_path), exist_ok=True)
    with open(full_path, 'w', encoding='utf-8') as f:
        f.write(output)
    print(f"\nAnalysis saved to: {full_path}")
    
    print("Analysis Summary\n")
    print(output_formatter.generate_tree_string(data))
    print(output_formatter.generate_summary_string(data))

if __name__ == "__main__":
    main()

==================================================
File: ./src/codebase_dump/__init__.py
==================================================


==================================================
File: ./src/codebase_dump/core/__init__.py
==================================================


==================================================
File: ./src/codebase_dump/core/codebase_analysis.py
==================================================
import os

from codebase_dump.core.ignore_patterns_manager import IgnorePatternManager
from codebase_dump.core.models import DirectoryAnalysis, TextFileAnalysis

class CodebaseAnalysis:

    def is_text_file_old(self, file_path):
        """Determines if a file is likely a text file based on its content."""
        try:
            with open(file_path, 'rb') as file:
                chunk = file.read(1024)
            return not bool(chunk.translate(None, bytes([7, 8, 9, 10, 12, 13, 27] + list(range(0x20, 0x100)))))
        except IOError:
            return False

    def is_text_file(self, file_path):
        try:
            with open(file_path, 'r') as file:
                file.read()
            return True
        except UnicodeDecodeError:
            return False
        except FileNotFoundError:
            print("File not found.")
            return False

    def read_file_content(self, file_path):
        """Reads the content of a file, handling potential encoding errors."""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                return f.read()
        except Exception as e:
            return f"Error reading file: {str(e)}"

    def analyze_directory(self, path, ignore_patterns_manager: IgnorePatternManager, base_path, max_depth=None, current_depth=0) -> DirectoryAnalysis:
        """Recursively analyzes a directory and its contents."""
        if max_depth is not None and current_depth > max_depth:
            return None

        result = DirectoryAnalysis(name=os.path.basename(path))
        try:
            for item in os.listdir(path):                
                item_path = os.path.join(path, item)
                
                is_ignored = ignore_patterns_manager.should_ignore(item_path, base_path)
                print(f"Debug: Checking {item_path}, ignored: {is_ignored}")  # Debug line

                if os.path.isfile(item_path) and self.is_text_file(item_path):
                    file_size = os.path.getsize(item_path)

                if is_ignored:
                    continue  # Skip ignored items for further analysis

                if os.path.isfile(item_path):
                    file_size = os.path.getsize(item_path)
                    if self.is_text_file(item_path):
                        content = self.read_file_content(item_path)
                        print(f"Debug: Text file {item_path}, size: {file_size}, content size: {len(content)}")
                    else:
                        content = "[Non-text file]"
                        print(f"Debug: Non-text file {item_path}, size: {file_size}")

                    child = TextFileAnalysis(name=item, file_content=content, is_ignored=is_ignored)
                    result.children.append(child)
                elif os.path.isdir(item_path):
                    subdir = self.analyze_directory(item_path, ignore_patterns_manager, base_path, max_depth, current_depth + 1)
                    if subdir:
                        subdir.is_ignored = is_ignored
                        result.children.append(subdir)
                        
        except PermissionError:
            print(f"Permission denied: {path}")

        return result

==================================================
File: ./src/codebase_dump/core/output_formatter.py
==================================================
from codebase_dump.core.models import DirectoryAnalysis, NodeAnalysis, TextFileAnalysis
import os

class OutputFormatterBase:
    def output_file_extension(self):
        raise NotImplemented

    def format(self, data: DirectoryAnalysis) -> str:
        raise NotImplemented
    
    def generate_tree_string(self, node: NodeAnalysis, prefix="", is_last=True, show_size=False, show_ignored=False):
        """Generates a string representation of the directory tree."""
        if node.is_ignored and not show_ignored:
            return ""

        result = prefix + ("└── " if is_last else "├── ") + node.name

        if show_size and isinstance(node, TextFileAnalysis):
            result += f" ({node.size} bytes)"

        if node.is_ignored:
            result += " [IGNORED]"

        result += "\n"

        if isinstance(node, DirectoryAnalysis):
            prefix += "    " if is_last else "│   "
            children = node.children
            if not show_ignored:
                children = [child for child in children if not child.is_ignored]
            for i, child in enumerate(children):
                result += self.generate_tree_string(child, prefix, i == len(children) - 1, show_size, show_ignored)
        return result
    
    def generate_content_string(self, data: NodeAnalysis):
        """Generates a structured representation of file contents."""
        content = []

        def add_file_content(node, path=""):
            if isinstance(node, TextFileAnalysis) and not node.is_ignored and node.file_content != "[Non-text file]":
                content.append({
                    "path": os.path.join(path, node.name),
                    "content": node.file_content
                })
            elif isinstance(node, DirectoryAnalysis):
                for child in node.children:
                    add_file_content(child, os.path.join(path, node.name))

        add_file_content(data)
        return content
    
    def generate_summary_string(self, data: DirectoryAnalysis):
        summary = "\nSummary:\n"
        summary += f"Total files analyzed: {data.get_file_count()}\n"
        summary += f"Total directories analyzed: {data.get_dir_count()}\n"
        summary += f"Estimated output size: {data.size / 1024:.2f} KB\n"
        summary += f"Actual analyzed size: {data.get_non_ignored_text_content_size() / 1024:.2f} KB\n"
        summary += f"Total tokens: {data.get_total_tokens()}\n"
        summary += f"Actual text content size: {data.size / 1024:.2f} KB\n"
        
        return summary
    
class PlainTextOutputFormatter(OutputFormatterBase):
    def output_file_extension(self):
        return ".txt"
    
    def format(self, data: DirectoryAnalysis) -> str:
        output = f"Codebase Analysis for: {data.name}\n"
        output += "\nDirectory Structure:\n"
        output += self.generate_tree_string(data, show_size=True, show_ignored=True)
        output += self.generate_summary_string(data)
        output += "\nFile Contents:\n"
        for file in self.generate_content_string(data):
            output += f"\n{'=' * 50}\n"
            output += f"File: {file['path']}\n"
            output += f"{'=' * 50}\n"
            output += file['content']
            output += "\n"
        return output

class MarkdownOutputFormatter(OutputFormatterBase):
    def output_file_extension(self):
        return ".md"
    
    def format(self, data: DirectoryAnalysis) -> str:
        output = f"# Codebase Analysis for: {data.name}\n\n"
        output += "## Directory Structure\n\n"
        output += "```\n"
        output += self.generate_tree_string(data, show_size=True, show_ignored=True)
        output += "```\n\n"
        output += "## Summary\n\n"
        output += f"- Total files: {data.get_file_count()}\n"
        output += f"- Total directories: {data.get_dir_count()}\n"
        output += f"- Total text file size (including ignored): {data.size / 1024:.2f} KB\n"
        output += f"- Total tokens: {data.get_total_tokens()}\n"
        output += f"- Analyzed text content size: {data.get_non_ignored_text_content_size() / 1024:.2f} KB\n\n"
        output += "## File Contents\n\n"
        for file in self.generate_content_string(data):
            output += f"### {file['path']}\n\n```\n{file['content']}\n```\n\n"
        return output

==================================================
File: ./src/codebase_dump/core/models.py
==================================================
from dataclasses import dataclass, field
from typing import List, Union
import tiktoken

@dataclass
class NodeAnalysis:
    name: str = ""
    is_ignored: bool = False

    @property
    def type(self) -> str:
        return NotImplemented
    
    @property
    def size(self) -> int:
        return NotImplemented
    
    def to_dict(self):
        return NotImplemented

@dataclass
class TextFileAnalysis(NodeAnalysis):
    file_content: str = ""

    @property
    def type(self) -> str:
        return "text_file"
    
    @property
    def size(self) -> int:
        return len(self.file_content)
    
    def count_tokens(self):
        """Counts the number of tokens in a text string."""
        enc = tiktoken.get_encoding("cl100k_base")
        try:
            return len(enc.encode(self.file_content, disallowed_special=()))
        except Exception as e:
            print(f"Warning: Error counting tokens: {str(e)}")
            return 0
        
    def to_dict(self):
        return {
            "name": self.name,
            "type": self.type,
            "size": self.size,
            "is_ignored": self.is_ignored,
            "content": self.file_content
        }

@dataclass
class DirectoryAnalysis(NodeAnalysis):
    children: List[Union["DirectoryAnalysis", TextFileAnalysis]] = field(default_factory=list)

    @property
    def type(self) -> str:
        return "directory"

    def get_file_count(self) -> int:
        count = 0
        for child in self.children:
            if child.is_ignored:
                continue

            if isinstance(child, TextFileAnalysis):
                count += 1
            if isinstance(child, DirectoryAnalysis):
                count += child.get_file_count()
        return count
    
    def get_dir_count(self) -> int:
       count = 0
       for child in self.children:
           if child.is_ignored:
               continue 
           
           if isinstance(child, DirectoryAnalysis):
               count += 1 + child.get_dir_count()
       return count


    def get_total_tokens(self) -> int:
        tokens = 0
        for child in self.children:
            if child.is_ignored:
                continue

            if isinstance(child, TextFileAnalysis):
                tokens += child.count_tokens()
            elif isinstance(child, DirectoryAnalysis):
                tokens += child.get_total_tokens()
        return tokens

    @property
    def size(self) -> int:
        size = 0
        for child in self.children:
            if isinstance(child, TextFileAnalysis):
                 size += child.size
            elif isinstance(child, DirectoryAnalysis):
                 size += child.size

        return size

    def get_non_ignored_text_content_size(self) -> int:
        size = 0
        for child in self.children:
            if child.is_ignored:
                continue    

            if isinstance(child, TextFileAnalysis) and child.file_content:
                size += len(child.file_content)
            elif isinstance(child, DirectoryAnalysis):
               size += child.size
        return size
    
    def to_dict(self):
        return {
            "name": self.name,
            "type": self.type,
            "size": self.size,
            "is_ignored": self.is_ignored,
            "non_ignored_text_content_size": self.get_non_ignored_text_content_size(),
            "total_tokens": self.get_total_tokens(),
            "file_count": self.get_file_count(),
            "dir_count": self.get_dir_count(),
            "children": [child.to_dict() for child in self.children]
        }

==================================================
File: ./src/codebase_dump/core/ignore_patterns_manager.py
==================================================
import os
import fnmatch
import re

# TODO: Add support for negation patterns
class IgnorePatternManager:

    DEFAULT_IGNORE_PATTERNS = [
        '*.pyc', '*.pyo', '*.pyd', '__pycache__',  # Python
        'node_modules', 'bower_components',        # JavaScript
        '.git', '.svn', '.hg', '.gitignore',       # Version control
        'venv', '.venv', 'env',                    # Virtual environments
        '.idea', '.vscode',                        # IDEs
        '*.log', '*.bak', '*.swp', '*.tmp',        # Temporary and log files
        '.DS_Store',                               # macOS
        'Thumbs.db',                               # Windows
        'build', 'dist',                           # Build directories
        '*.egg-info',                              # Python egg info
        '*.so', '*.dylib', '*.dll'                 # Compiled libraries
    ]

    def __init__(self, 
                 base_path,
                 load_default_ignore_patterns=True, 
                 load_gitignore=True, 
                 load_cdigestignore=True,
                 extra_ignore_patterns=set()):
        self.base_path = base_path
        self.load_default_ignore_patterns=load_default_ignore_patterns
        self.load_gitignore=load_gitignore
        self.load_cdigestignore = load_cdigestignore
        self.extra_ignore_patterns = extra_ignore_patterns

        self.ignore_patterns = set()
        self.ignore_patterns_as_str = set()

        self.init_ignore_patterns()


    def init_ignore_patterns(self):
        self.ignore_patterns = set()

        if self.load_default_ignore_patterns:
            for pattern in IgnorePatternManager.DEFAULT_IGNORE_PATTERNS:
                self.ignore_patterns_as_str.add(pattern)
                self.ignore_patterns.add(self.str_to_regex(pattern))
        
        if self.extra_ignore_patterns:
            for pattern in self.extra_ignore_patterns:
                self.ignore_patterns_as_str.add(pattern)
                self.ignore_patterns.add(self.str_to_regex(pattern))
        
        cdigestignore_path = os.path.join(self.base_path, '.cdigestignore')
        if self.load_cdigestignore and os.path.exists(cdigestignore_path):
            regex_patterns, string_patterns = self.parse_gitignore(cdigestignore_path)
            self.ignore_patterns_as_str.update(string_patterns)
            self.ignore_patterns.update(regex_patterns)
        
        gitignore_path = os.path.join(self.base_path, '.gitignore')
        if self.load_gitignore and os.path.exists(gitignore_path):
            regex_patterns, string_patterns = self.parse_gitignore(gitignore_path)
            self.ignore_patterns_as_str.update(string_patterns)
            self.ignore_patterns.update(regex_patterns)

    
    def parse_gitignore(self, gitignore_path=".gitignore"):
        """Parses a .gitignore file and returns a list of compiled regex patterns."""
        regex_patterns = []
        string_patterns = []
        with open(gitignore_path, "r") as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith("#"):
                    continue
                
                string_patterns.append(line)
                regex_patterns.append(self.str_to_regex(line))
        return regex_patterns, string_patterns

    def str_to_regex(self, pattern):
        """Converts a glob pattern to a regex pattern."""
        if pattern is None:
            return None

        is_directory_pattern = pattern.endswith("/")

        regex = re.escape(pattern).replace(r"\*", ".*").replace(r"\?", ".")

        if is_directory_pattern:
            # Match directories by ensuring a trailing slash or end of path
            regex = f"(?:.*/)?{regex.rstrip('/')}/?$"
        else:
            # Match regular files or paths
            regex = f"(?:.*/)?{regex}(?:/.*)?$"

        return re.compile(regex)

    def should_ignore(self, path, base_path):
        """Checks if a file or directory should be ignored based on patterns."""
        for pattern in self.ignore_patterns:
            if pattern.match(path):
                return True
        return False
